#!/bin/bash

# BEwithU Ollama å¯åŠ¨è„šæœ¬
# è‡ªåŠ¨ä¸‹è½½å’Œé…ç½®æŽ¨èçš„LLMæ¨¡åž‹

echo "ðŸš€ å¯åŠ¨ BEwithU Ollama æœåŠ¡..."

# å¯åŠ¨OllamaæœåŠ¡
ollama serve &
OLLAMA_PID=$!

# ç­‰å¾…OllamaæœåŠ¡å¯åŠ¨
echo "â³ ç­‰å¾… Ollama æœåŠ¡å¯åŠ¨..."
sleep 10

# æ£€æŸ¥Ollamaæ˜¯å¦æ­£å¸¸è¿è¡Œ
while ! curl -f http://localhost:11434/api/tags >/dev/null 2>&1; do
    echo "â³ ç­‰å¾… Ollama æœåŠ¡å°±ç»ª..."
    sleep 5
done

echo "âœ… Ollama æœåŠ¡å·²å¯åŠ¨"

# ä¸‹è½½æŽ¨èçš„æ¨¡åž‹
echo "ðŸ“¥ å¼€å§‹ä¸‹è½½æŽ¨èçš„ LLM æ¨¡åž‹..."

# ä¸»è¦æ¨¡åž‹ï¼šLlama 3.1 8Bï¼ˆé€šç”¨å¯¹è¯ï¼‰
if ! ollama list | grep -q "llama3.1:8b"; then
    echo "ðŸ“¥ ä¸‹è½½ Llama 3.1 8B æ¨¡åž‹ï¼ˆé€šç”¨å¯¹è¯ï¼‰..."
    ollama pull llama3.1:8b
    echo "âœ… Llama 3.1 8B æ¨¡åž‹ä¸‹è½½å®Œæˆ"
else
    echo "âœ… Llama 3.1 8B æ¨¡åž‹å·²å­˜åœ¨"
fi

# ä¸­æ–‡ä¼˜åŒ–æ¨¡åž‹ï¼šQwen2 7B
if ! ollama list | grep -q "qwen2:7b"; then
    echo "ðŸ“¥ ä¸‹è½½ Qwen2 7B æ¨¡åž‹ï¼ˆä¸­æ–‡ä¼˜åŒ–ï¼‰..."
    ollama pull qwen2:7b
    echo "âœ… Qwen2 7B æ¨¡åž‹ä¸‹è½½å®Œæˆ"
else
    echo "âœ… Qwen2 7B æ¨¡åž‹å·²å­˜åœ¨"
fi

# ä»£ç å’ŒæŽ¨ç†æ¨¡åž‹ï¼šMistral 7B
if ! ollama list | grep -q "mistral:7b"; then
    echo "ðŸ“¥ ä¸‹è½½ Mistral 7B æ¨¡åž‹ï¼ˆä»£ç å’ŒæŽ¨ç†ï¼‰..."
    ollama pull mistral:7b
    echo "âœ… Mistral 7B æ¨¡åž‹ä¸‹è½½å®Œæˆ"
else
    echo "âœ… Mistral 7B æ¨¡åž‹å·²å­˜åœ¨"
fi

# è½»é‡çº§æ¨¡åž‹ï¼šPhi-3 Miniï¼ˆå¿«é€Ÿå“åº”ï¼‰
if ! ollama list | grep -q "phi3:mini"; then
    echo "ðŸ“¥ ä¸‹è½½ Phi-3 Mini æ¨¡åž‹ï¼ˆå¿«é€Ÿå“åº”ï¼‰..."
    ollama pull phi3:mini
    echo "âœ… Phi-3 Mini æ¨¡åž‹ä¸‹è½½å®Œæˆ"
else
    echo "âœ… Phi-3 Mini æ¨¡åž‹å·²å­˜åœ¨"
fi

echo "ðŸŽ‰ æ‰€æœ‰æŽ¨èæ¨¡åž‹ä¸‹è½½å®Œæˆï¼"

# æ˜¾ç¤ºå·²å®‰è£…çš„æ¨¡åž‹
echo "ðŸ“‹ å·²å®‰è£…çš„æ¨¡åž‹åˆ—è¡¨ï¼š"
ollama list

# åˆ›å»ºæ¨¡åž‹é…ç½®æ–‡ä»¶
cat > /root/.ollama/models.json << EOF
{
  "models": {
    "primary": {
      "name": "llama3.1:8b",
      "description": "ä¸»è¦å¯¹è¯æ¨¡åž‹ï¼Œé€‚ç”¨äºŽä¸€èˆ¬æŸ¥è¯¢å’Œå¯¹è¯",
      "use_case": "general_chat",
      "languages": ["ja", "en", "zh"]
    },
    "chinese": {
      "name": "qwen2:7b", 
      "description": "ä¸­æ–‡ä¼˜åŒ–æ¨¡åž‹ï¼Œé€‚ç”¨äºŽä¸­æ–‡å†…å®¹å¤„ç†",
      "use_case": "chinese_content",
      "languages": ["zh", "ja", "en"]
    },
    "code": {
      "name": "mistral:7b",
      "description": "ä»£ç å’ŒæŽ¨ç†æ¨¡åž‹ï¼Œé€‚ç”¨äºŽæŠ€æœ¯é—®é¢˜",
      "use_case": "technical_support",
      "languages": ["en", "ja"]
    },
    "fast": {
      "name": "phi3:mini",
      "description": "è½»é‡çº§å¿«é€Ÿå“åº”æ¨¡åž‹",
      "use_case": "quick_response",
      "languages": ["en", "ja"]
    }
  },
  "default_model": "llama3.1:8b",
  "fallback_model": "phi3:mini"
}
EOF

echo "ðŸ“ æ¨¡åž‹é…ç½®æ–‡ä»¶å·²åˆ›å»º"

# æµ‹è¯•æ¨¡åž‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
echo "ðŸ§ª æµ‹è¯•æ¨¡åž‹åŠŸèƒ½..."

# æµ‹è¯•ä¸»è¦æ¨¡åž‹
echo "Testing primary model..." | ollama run llama3.1:8b "Please respond with 'Model test successful' if you can understand this message."

echo "ðŸŽ¯ BEwithU Ollama æœåŠ¡é…ç½®å®Œæˆï¼"
echo "ðŸŒ API ç«¯ç‚¹: http://localhost:11434"
echo "ðŸ“š å¯ç”¨æ¨¡åž‹: llama3.1:8b, qwen2:7b, mistral:7b, phi3:mini"

# ä¿æŒOllamaæœåŠ¡è¿è¡Œ
wait $OLLAMA_PID

